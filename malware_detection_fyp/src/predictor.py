"""
CyberShield AI - Malware Detection Predictor
Advanced neural network inference engine for malware classification.

Features:
- Real-time malware detection
- Detailed threat analysis
- Confidence scoring
- Feature extraction and visualization
"""

import os
import sys
import numpy as np
import cv2
import json
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.data_loader import CorrectMalwareDataLoader

class CorrectMalwarePredictor:
    def __init__(self, model_path=None, model_info_path=None):
        """
        Initialize the correct malware predictor
        
        Args:
            model_path: Path to the trained model file
            model_info_path: Path to the model info JSON file
        """
        self.model = None
        self.class_mapping = None
        self.target_size = (256, 256)
        self.model_info = None
        
        if model_path and os.path.exists(model_path):
            self.load_model(model_path, model_info_path)
    
    def load_model(self, model_path, model_info_path=None):
        """Load the trained model and its metadata"""
        print(f"Loading model from: {model_path}")
        
        try:
            self.model = load_model(model_path)
            print("Model loaded successfully!")
            
            # Load model info if available
            if model_info_path and os.path.exists(model_info_path):
                with open(model_info_path, 'r') as f:
                    self.model_info = json.load(f)
                    self.class_mapping = self.model_info.get('class_mapping', {})
                    config = self.model_info.get('config', {})
                    self.target_size = tuple(config.get('target_size', (256, 256)))
                    
                print(f"Model info loaded. Classes: {len(self.class_mapping)}")
            else:
                # Default class mapping
                self.class_mapping = {
                    'Adialer.C': 0, 'Agent.FYI': 1, 'Allaple.A': 2, 'Allaple.L': 3,
                    'Alueron.gen!J': 4, 'Autorun.K': 5, 'C2LOP.P': 6, 'C2LOP.gen!g': 7,
                    'Dialplatform.B': 8, 'Dontovo.A': 9, 'Fakerean': 10, 'Instantaccess': 11,
                    'Lolyda.AA1': 12, 'Lolyda.AA2': 13, 'Lolyda.AA3': 14, 'Lolyda.AT': 15,
                    'Malex.gen!J': 16, 'Obfuscator.AD': 17, 'Rbot!gen': 18, 'Skintrim.N': 19,
                    'Swizzor.gen!E': 20, 'Swizzor.gen!I': 21, 'VB.AT': 22, 'Wintrim.BX': 23,
                    'Yuner.A': 24, 'Benign': 25
                }
                print("Using default class mapping")
            
            # Create reverse mapping
            self.index_to_class = {v: k for k, v in self.class_mapping.items()}
            
        except Exception as e:
            print(f"Error loading model: {e}")
            raise
    
    def preprocess_image(self, image_path):
        """
        Preprocess image for prediction following reference approach
        
        Args:
            image_path: Path to the image file
            
        Returns:
            Preprocessed image array
        """
        # Load image
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Could not load image: {image_path}")
        
        # Resize to target size
        img = cv2.resize(img, self.target_size)
        
        # Normalize pixel values (following reference: rescale=1/255.0)
        img = img.astype(np.float32) / 255.0
        
        # Add batch dimension
        img = np.expand_dims(img, axis=0)
        
        return img
    
    def predict_single_image(self, image_path, return_probabilities=False):
        """
        Predict malware family for a single image
        
        Args:
            image_path: Path to the image file
            return_probabilities: Whether to return class probabilities
            
        Returns:
            Prediction result dictionary
        """
        if self.model is None:
            raise ValueError("Model not loaded. Call load_model() first.")
        
        # Preprocess image
        img_array = self.preprocess_image(image_path)
        
        # Make prediction
        predictions = self.model.predict(img_array, verbose=0)
        predicted_class_idx = np.argmax(predictions[0])
        confidence = float(predictions[0][predicted_class_idx])
        
        # Get class name
        predicted_class = self.index_to_class.get(predicted_class_idx, f"Unknown_{predicted_class_idx}")
        
        # Determine if malware or benign
        is_malware = predicted_class != 'Benign'
        
        result = {
            'image_path': image_path,
            'predicted_class': predicted_class,
            'predicted_index': int(predicted_class_idx),
            'confidence': confidence,
            'is_malware': is_malware,
            'malware_type': predicted_class if is_malware else None
        }
        
        if return_probabilities:
            # Get top 5 predictions
            top_indices = np.argsort(predictions[0])[::-1][:5]
            top_predictions = []
            
            for idx in top_indices:
                class_name = self.index_to_class.get(idx, f"Unknown_{idx}")
                prob = float(predictions[0][idx])
                top_predictions.append({
                    'class': class_name,
                    'probability': prob,
                    'index': int(idx)
                })
            
            result['top_predictions'] = top_predictions
            result['all_probabilities'] = predictions[0].tolist()
        
        return result
    
    def analyze_image_features(self, image_path):
        """
        Analyze image features that the model uses for classification
        
        Args:
            image_path: Path to the image file
            
        Returns:
            Dictionary with image analysis
        """
        # Load and preprocess image
        img = cv2.imread(image_path)
        if img is None:
            return None
        
        # Convert to grayscale for analysis
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Calculate various features
        analysis = {
            'file_path': image_path,
            'image_shape': img.shape,
            'grayscale_stats': {
                'mean': float(np.mean(gray)),
                'std': float(np.std(gray)),
                'min': int(np.min(gray)),
                'max': int(np.max(gray)),
                'entropy': self._calculate_entropy(gray)
            },
            'texture_features': self._analyze_texture(gray),
            'structural_features': self._analyze_structure(gray)
        }
        
        return analysis
    
    def _calculate_entropy(self, image):
        """Calculate entropy of grayscale image"""
        hist, _ = np.histogram(image, bins=256, range=(0, 256))
        hist = hist[hist > 0]  # Remove zero entries
        prob = hist / np.sum(hist)
        entropy = -np.sum(prob * np.log2(prob))
        return float(entropy)
    
    def _analyze_texture(self, gray_image):
        """Analyze texture features"""
        # Calculate local binary patterns-like features
        rows, cols = gray_image.shape
        
        # Simple texture measures
        # Horizontal gradient
        grad_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)
        # Vertical gradient  
        grad_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)
        
        # Gradient magnitude
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        
        return {
            'gradient_mean': float(np.mean(gradient_magnitude)),
            'gradient_std': float(np.std(gradient_magnitude)),
            'edge_density': float(np.sum(gradient_magnitude > np.mean(gradient_magnitude)) / (rows * cols))
        }
    
    def _analyze_structure(self, gray_image):
        """Analyze structural features"""
        # Calculate structural patterns
        rows, cols = gray_image.shape
        
        # Row-wise and column-wise variance (indicates structure)
        row_variance = np.var(gray_image, axis=1)
        col_variance = np.var(gray_image, axis=0)
        
        # Pattern regularity
        row_patterns = np.mean(row_variance)
        col_patterns = np.mean(col_variance)
        
        return {
            'row_pattern_strength': float(row_patterns),
            'col_pattern_strength': float(col_patterns),
            'structure_ratio': float(row_patterns / (col_patterns + 1e-8)),
            'pattern_regularity': float(np.std(row_variance) + np.std(col_variance))
        }
    
    def predict_with_analysis(self, image_path):
        """
        Predict malware class with detailed analysis
        
        Args:
            image_path: Path to the image file
            
        Returns:
            Combined prediction and analysis results
        """
        # Get prediction
        prediction = self.predict_single_image(image_path, return_probabilities=True)
        
        # Get image analysis
        analysis = self.analyze_image_features(image_path)
        
        # Combine results
        result = {
            'prediction': prediction,
            'analysis': analysis,
            'explanation': self._generate_explanation(prediction, analysis)
        }
        
        return result
    
    def _generate_explanation(self, prediction, analysis):
        """Generate human-readable explanation of the prediction"""
        
        if analysis is None:
            return "Could not analyze image features."
        
        explanation = []
        
        # Basic prediction info
        if prediction['is_malware']:
            explanation.append(f"Classified as MALWARE: {prediction['predicted_class']}")
            explanation.append(f"Confidence: {prediction['confidence']:.2%}")
        else:
            explanation.append(f"Classified as BENIGN software")
            explanation.append(f"Confidence: {prediction['confidence']:.2%}")
        
        # Feature analysis
        grayscale_stats = analysis['grayscale_stats']
        texture_features = analysis['texture_features']
        structural_features = analysis['structural_features']
        
        explanation.append(f"\\nImage Analysis:")
        explanation.append(f"- Entropy: {grayscale_stats['entropy']:.2f} (randomness measure)")
        explanation.append(f"- Edge density: {texture_features['edge_density']:.3f} (texture complexity)")
        explanation.append(f"- Pattern regularity: {structural_features['pattern_regularity']:.2f}")
        
        # Interpretation
        if grayscale_stats['entropy'] > 7.0:
            explanation.append("- High entropy suggests complex binary structure")
        elif grayscale_stats['entropy'] < 5.0:
            explanation.append("- Low entropy suggests simple or repetitive structure")
        
        if texture_features['edge_density'] > 0.3:
            explanation.append("- High edge density indicates complex code patterns")
        
        return "\\n".join(explanation)
    
    def batch_predict(self, image_paths, output_file=None):
        """
        Predict multiple images
        
        Args:
            image_paths: List of image paths
            output_file: Optional file to save results
            
        Returns:
            List of prediction results
        """
        results = []
        
        print(f"Processing {len(image_paths)} images...")
        
        for i, image_path in enumerate(image_paths):
            try:
                result = self.predict_with_analysis(image_path)
                results.append(result)
                
                if (i + 1) % 10 == 0:
                    print(f"Processed {i + 1}/{len(image_paths)} images")
                    
            except Exception as e:
                print(f"Error processing {image_path}: {e}")
                results.append({
                    'image_path': image_path,
                    'error': str(e)
                })
        
        # Save results if requested
        if output_file:
            with open(output_file, 'w') as f:
                json.dump(results, f, indent=2)
            print(f"Results saved to: {output_file}")
        
        return results

def main():
    """Example usage of the correct predictor"""
    
    # Find the latest model
    models_dir = "models"
    if not os.path.exists(models_dir):
        print("No models directory found. Please train a model first.")
        return
    
    model_files = [f for f in os.listdir(models_dir) if f.endswith('.keras')]
    if not model_files:
        print("No trained models found. Please train a model first.")
        return
    
    # Use the latest model
    latest_model = sorted(model_files)[-1]
    model_path = os.path.join(models_dir, latest_model)
    
    # Look for corresponding info file
    model_info_path = model_path.replace('.keras', '_info.json')
    if not os.path.exists(model_info_path):
        # Try alternative naming
        timestamp = latest_model.split('_')[-1].replace('.keras', '')
        model_info_path = os.path.join(models_dir, f"model_info_{timestamp}.json")
    
    print(f"Using model: {model_path}")
    
    # Initialize predictor
    predictor = CorrectMalwarePredictor(model_path, model_info_path)
    
    # Example prediction (replace with actual image path)
    test_image = "test_images/sample_malware.png"
    if os.path.exists(test_image):
        result = predictor.predict_with_analysis(test_image)
        
        print("\\nPrediction Result:")
        print("=" * 50)
        print(result['explanation'])
        
        if 'top_predictions' in result['prediction']:
            print("\\nTop 5 Predictions:")
            for pred in result['prediction']['top_predictions']:
                print(f"  {pred['class']}: {pred['probability']:.3f}")
    else:
        print(f"Test image not found: {test_image}")
        print("Please provide a valid image path for testing.")

if __name__ == "__main__":
    main()